"""
OpenAI API endpoints
"""

import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model
from app.utils.helpers import debug_log
from app.core.zai_transformer import ZAITransformer, generate_uuid
from app.utils.sse_tool_handler import SSEToolHandler

router = APIRouter()

# å…¨å±€è½¬æ¢å™¨å®ä¾‹
transformer = ZAITransformer()


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    role = request.messages[0].role if request.messages else "unknown"
    debug_log(f"ğŸ˜¶â€ğŸŒ«ï¸ æ”¶åˆ° å®¢æˆ·ç«¯ è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}, æ¶ˆæ¯æ•°: {len(request.messages)}, è§’è‰²: {role}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")
    
    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")
            
            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                raise HTTPException(status_code=401, detail="Invalid API key")
            
        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        request_dict = request.model_dump()
        debug_log("ğŸ”„ å¼€å§‹è½¬æ¢è¯·æ±‚æ ¼å¼: OpenAI -> Z.AI")
        
        transformed = await transformer.transform_request_in(request_dict)

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None
            current_token = transformed.get("token", "")  # è·å–å½“å‰ä½¿ç”¨çš„token

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = 2.0
                        debug_log(f"é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - ç­‰å¾… {delay:.1f}s")
                        await asyncio.sleep(delay)

                        # æ ‡è®°å‰ä¸€ä¸ªtokenå¤±è´¥
                        if current_token:
                            transformer.mark_token_failure(current_token, Exception(f"Retry {retry_count}: {last_error}"))

                        # é‡æ–°è·å–ä»¤ç‰Œ
                        debug_log("ğŸ”‘ é‡æ–°è·å–ä»¤ç‰Œç”¨äºé‡è¯•...")
                        new_token = await transformer.get_token()
                        if not new_token:
                            debug_log("âŒ é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                            raise Exception("é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                        transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                        current_token = new_token

                    async with httpx.AsyncClient(timeout=60.0) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        debug_log(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})")
                                debug_log(f"ä¸Šæ¸¸é”™è¯¯å“åº”: {error_msg}")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œç›´æ¥è¿”å›
                                debug_log(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}")
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                debug_log(f"âŒ é”™è¯¯è¯¦æƒ…: {error_msg}")

                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            debug_log(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                debug_log(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # æ ‡è®°tokenä½¿ç”¨æˆåŠŸ
                            if current_token:
                                transformer.mark_token_success(current_token)

                            # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            has_tools = transformed["body"].get("tools") is not None
                            has_mcp_servers = bool(transformed["body"].get("mcp_servers"))
                            tool_handler = None

                            # å¦‚æœæœ‰å·¥å…·å®šä¹‰æˆ–MCPæœåŠ¡å™¨ï¼Œéƒ½éœ€è¦å·¥å…·å¤„ç†å™¨
                            if has_tools or has_mcp_servers:
                                chat_id = transformed["body"]["chat_id"]
                                model = request.model
                                tool_handler = SSEToolHandler(chat_id, model)

                                if has_tools and has_mcp_servers:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…· + {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")
                                elif has_tools:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªOpenAIå·¥å…·")
                                elif has_mcp_servers:
                                    debug_log(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('mcp_servers', []))} ä¸ªMCPæœåŠ¡å™¨")

                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None

                            # å¤„ç†SSEæµ
                            buffer = ""
                            line_count = 0
                            debug_log("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for line in response.aiter_lines():
                                line_count += 1
                                if not line:
                                    continue

                                # ç´¯ç§¯åˆ°bufferå¤„ç†å®Œæ•´çš„æ•°æ®è¡Œ
                                buffer += line + "\n"

                                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„dataè¡Œ
                                while "\n" in buffer:
                                    current_line, buffer = buffer.split("\n", 1)
                                    if not current_line.strip():
                                        continue

                                    if current_line.startswith("data:"):
                                        chunk_str = current_line[5:].strip()
                                        if not chunk_str or chunk_str == "[DONE]":
                                            if chunk_str == "[DONE]":
                                                yield "data: [DONE]\n\n"
                                            continue

                                        debug_log(f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:200]}..." if len(chunk_str) > 200 else f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                                        try:
                                            chunk = json.loads(chunk_str)

                                            if chunk.get("type") == "chat:completion":
                                                data = chunk.get("data", {})
                                                phase = data.get("phase")

                                                # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                if phase and phase != getattr(stream_response, '_last_phase', None):
                                                    debug_log(f"ğŸ“ˆ SSE é˜¶æ®µ: {phase}")
                                                    stream_response._last_phase = phase

                                                # å¤„ç†å·¥å…·è°ƒç”¨
                                                if phase == "tool_call" and tool_handler:
                                                    for output in tool_handler.process_tool_call_phase(data, True):
                                                        yield output

                                                # å¤„ç†å…¶ä»–é˜¶æ®µï¼ˆå·¥å…·ç»“æŸï¼‰
                                                elif phase == "other" and tool_handler:
                                                    for output in tool_handler.process_other_phase(data, True):
                                                        yield output

                                                # å¤„ç†æ€è€ƒå†…å®¹
                                                elif phase == "thinking":
                                                    if not has_thinking:
                                                        has_thinking = True
                                                        # å‘é€åˆå§‹è§’è‰²
                                                        role_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {"role": "assistant"},
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                                    delta_content = data.get("delta_content", "")
                                                    if delta_content:
                                                        # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                        if delta_content.startswith("<details"):
                                                            content = (
                                                                delta_content.split("</summary>\n>")[-1].strip()
                                                                if "</summary>\n>" in delta_content
                                                                else delta_content
                                                            )
                                                        else:
                                                            content = delta_content

                                                        thinking_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "thinking": {"content": content},
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                elif phase == "answer":
                                                    edit_content = data.get("edit_content", "")
                                                    delta_content = data.get("delta_content", "")

                                                    # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                    if edit_content and "</details>\n" in edit_content:
                                                        if has_thinking:
                                                            # å‘é€æ€è€ƒç­¾å
                                                            thinking_signature = str(int(time.time() * 1000))
                                                            sig_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "thinking": {
                                                                                "content": "",
                                                                                "signature": thinking_signature,
                                                                            },
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(sig_chunk)}\n\n"

                                                        # æå–ç­”æ¡ˆå†…å®¹
                                                        content_after = edit_content.split("</details>\n")[-1]
                                                        if content_after:
                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": content_after,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                    # å¤„ç†å¢é‡å†…å®¹
                                                    elif delta_content:
                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                        if not has_thinking:
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        content_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "content": delta_content,
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                        debug_log(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {output_data[:200]}...")
                                                        yield output_data

                                                    # å¤„ç†å®Œæˆ
                                                    if data.get("usage"):
                                                        debug_log(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # åªæœ‰åœ¨éå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹æ‰å‘é€æ™®é€šå®Œæˆä¿¡å·
                                                        if not tool_handler or not tool_handler.has_tool_call:
                                                            finish_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant", "content": ""},
                                                                        "finish_reason": "stop",
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "usage": data["usage"],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                            debug_log(f"â¡ï¸ å‘é€å®Œæˆä¿¡å·: {finish_output[:200]}...")
                                                            yield finish_output
                                                            debug_log("â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"

                                        except json.JSONDecodeError as e:
                                            debug_log(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:200]}")
                                        except Exception as e:
                                            debug_log(f"âŒ å¤„ç†chunké”™è¯¯: {e}")

                            # ç¡®ä¿å‘é€ç»“æŸä¿¡å·
                            if not tool_handler or not tool_handler.has_tool_call:
                                debug_log("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"

                            debug_log(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®")
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    debug_log(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    debug_log(traceback.format_exc())

                    # æ ‡è®°tokenå¤±è´¥
                    if current_token:
                        transformer.mark_token_failure(current_token, e)

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    if retry_count > settings.MAX_RETRIES:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                        debug_log(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                        error_response = {
                            "error": {
                                "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                "type": "stream_error"
                            }
                        }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

        # è¿”å›æµå¼å“åº”
        debug_log("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")
        
        # åˆ›å»ºä¸€ä¸ªåŒ…è£…çš„ç”Ÿæˆå™¨æ¥è¿½è¸ªæ•°æ®æµ
        async def logged_stream():
            chunk_count = 0
            try:
                debug_log("ğŸ“¤ å¼€å§‹å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“æ•°æ®...")
                async for chunk in stream_response():
                    chunk_count += 1
                    debug_log(f"ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk[:200]}..." if len(chunk) > 200 else f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk}")
                    yield chunk
                debug_log(f"âœ… æµå¼ä¼ è¾“å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
            except Exception as e:
                debug_log(f"âŒ æµå¼ä¼ è¾“ä¸­æ–­: {e}")
                raise
        
        return StreamingResponse(
            logged_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        debug_log(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        debug_log(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")